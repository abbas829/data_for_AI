{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 20px rgba(0,0,0,0.2);\">\n",
    "    <h1 style=\"color: white; border-bottom: 2px solid rgba(255,255,255,0.3); padding-bottom: 15px; margin-top: 0;\">\ud83e\udde0 The Perfect Math Roadmap for AI Beginners</h1>\n",
    "    <h2 style=\"color: #f1c40f; margin-top: 10px;\">From Zero to Hero: Master Linear Algebra, Calculus & Probability</h2>\n",
    "    <p style=\"font-size: 1.1em; margin-top: 20px;\">\n",
    "        <b>Welcome!</b> This notebook is designed to take you from \"I'm bad at math\" to \"I understand how AI works\". \n",
    "        We use <b style=\"color: #f1c40f;\">visualizations</b>, <b style=\"color: #f1c40f;\">analogies</b>, and <b style=\"color: #f1c40f;\">Python code</b> \n",
    "        to build your intuition. No boring proofs\u2014just what you need to build intelligent systems.\n",
    "    </p>\n",
    "    <hr style=\"border-color: rgba(255,255,255,0.2); margin: 20px 0;\">\n",
    "    <div style=\"display: flex; gap: 20px; align-items: center;\">\n",
    "        <div>\n",
    "            <b>\ud83d\udc64 Author:</b> Tassawar Abbas<br>\n",
    "            <b>\ud83d\udce7 Email:</b> <a href=\"mailto:abbas829@gmail.com\" style=\"color: #f1c40f; text-decoration: none;\">abbas829@gmail.com</a>\n",
    "        </div>\n",
    "        <div style=\"border-left: 1px solid rgba(255,255,255,0.3); padding-left: 20px;\">\n",
    "            <b>\ud83d\ude80 Goal:</b> Understand the \"Why\" and \"How\" of AI Math<br>\n",
    "            <b>\ud83d\udee0\ufe0f Level:</b> Beginner to Intermediate\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udee0\ufe0f 0. Setting Up Your Toolkit\n",
    "Before we start, we need our tools. In AI, these are:\n",
    "*   **NumPy**: The Swiss Army knife for numbers (vectors & matrices).\n",
    "*   **Matplotlib/Seaborn**: Seeing is believing (visualizations).\n",
    "*   **SciPy**: Advanced math functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Make plots look professional\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'figure.figsize': (10, 6),\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'lines.linewidth': 2.5,\n",
    "    'grid.alpha': 0.7\n",
    "})\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"\u2705 Toolkit Ready! Let's do some math.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcd0 Part 1: Linear Algebra (The Language of Data)\n",
    "## \"Think in Arrows and Grids\"\n",
    "\n",
    "Why do we need Linear Algebra?\n",
    "> **Because computers don't understand images, text, or sound. They only understand lists of numbers.**\n",
    "\n",
    "*   An **Image** is a grid of numbers (pixels).\n",
    "*   A **Word** is a list of numbers (vector embedding).\n",
    "*   **Linear Algebra** provides the rules for manipulating these lists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Vectors: Data Points in Space\n",
    "A **vector** is just a list of numbers. In geometry, it's an arrow pointing from the origin (0,0) to a point.\n",
    "\n",
    "**Analogy**: Think of a vector as a character's stats in a video game: `[Strength, Speed, Intelligence]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Creating a vector (game character stats)\n",
    "# [Strength, Speed]\n",
    "hero = np.array([3, 5])\n",
    "monster = np.array([4, 2])\n",
    "\n",
    "print(f\"Hero Stats: {hero}\")\n",
    "print(f\"Monster Stats: {monster}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.axhline(0, color='black', linewidth=1)\n",
    "plt.axvline(0, color='black', linewidth=1)\n",
    "\n",
    "# Plot vectors as arrows\n",
    "plt.quiver(0, 0, hero[0], hero[1], angles='xy', scale_units='xy', scale=1, color='#3498db', label='Hero')\n",
    "plt.quiver(0, 0, monster[0], monster[1], angles='xy', scale_units='xy', scale=1, color='#e74c3c', label='Monster')\n",
    "\n",
    "plt.xlim(-1, 6)\n",
    "plt.ylim(-1, 6)\n",
    "plt.xlabel('Strength')\n",
    "plt.ylabel('Speed')\n",
    "plt.title('Vectors as Arrows: Reviewing Character Stats')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Dot Product: Assessing Similarity\n",
    "The **Dot Product** is one of the most important operations in AI.\n",
    "It tells us **how similar** two vectors are (conceptually, whether they point in the same direction).\n",
    "\n",
    "Formula: $a \\cdot b = \\sum (a_i \times b_i)$\n",
    "\n",
    "> **Use Case in AI**: This is how **Recommendation Systems** work! If your \"User Vector\" is similar to a \"Movie Vector\", the dot product is high, and Netflix recommends it.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's see if our Hero and Monster are \"aligned\" (similar stats)\n",
    "\n",
    "# Calculate dot product\n",
    "dot_prod = np.dot(hero, monster)\n",
    "print(f\"Dot Product (Similarity Score): {dot_prod}\")\n",
    "\n",
    "# Let's compare with a Villain who is very different\n",
    "villain = np.array([-2, 4]) # Low strength (negative?), high speed\n",
    "\n",
    "dot_prod_villain = np.dot(hero, villain)\n",
    "print(f\"Dot Product with Villain: {dot_prod_villain}\")\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"High positive dot product = Similar direction (Alignment)\")\n",
    "print(\"Zero dot product = Orthogonal (Unrelated)\")\n",
    "print(\"Negative dot product = Opposite direction\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Matrices: Transformations\n",
    "If a vector is data, a **Matrix** is a machine that *transforms* that data.\n",
    "It can rotate, scale, or shear vectors.\n",
    "\n",
    "In Neural Networks, **layers are just matrices**. When data passes through a layer, the matrix transforms it to extract features.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define a rotation matrix (rotates 90 degrees counter-clockwise)\n",
    "theta = np.radians(90)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta),  np.cos(theta)]\n",
    "])\n",
    "\n",
    "print(\"Rotation Matrix:\\n\", rotation_matrix.round(2))\n",
    "\n",
    "# Apply transformation (Matrix-Vector Multiplication)\n",
    "# New Vector = Matrix @ Old Vector\n",
    "hero_rotated = rotation_matrix @ hero\n",
    "\n",
    "print(f\"Original Hero: {hero}\")\n",
    "print(f\"Rotated Hero: {hero_rotated.round(2)}\")\n",
    "\n",
    "# Visualizing the transformation\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.axhline(0, color='black', linewidth=1)\n",
    "plt.axvline(0, color='black', linewidth=1)\n",
    "\n",
    "# Original\n",
    "plt.quiver(0, 0, hero[0], hero[1], angles='xy', scale_units='xy', scale=1, color='#3498db', label='Original')\n",
    "# Rotated\n",
    "plt.quiver(0, 0, hero_rotated[0], hero_rotated[1], angles='xy', scale_units='xy', scale=1, color='#2ecc71', label='Transformed (Rotated)')\n",
    "\n",
    "plt.xlim(-6, 6)\n",
    "plt.ylim(-6, 6)\n",
    "plt.title('Matrices Transform Vectors (Here: 90\u00b0 Rotation)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcc9 Part 2: Calculus (The Engine of Learning)\n",
    "## \"How Neural Networks Learn from Mistakes\"\n",
    "\n",
    "Calculus in AI is largely about one thing: **Optimization**.\n",
    "We want to minimize the *error* (loss) of our model. To do that, we need to know generally \"which way is down?\"\n",
    "\n",
    "*   **Derivative**: The slope of a function at a point. It tells you the direction of steepest ascent/descent.\n",
    "*   **Gradient**: The derivative for multi-dimensional functions (like a landscape).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Derivative: Sensitivity\n",
    "Think of the derivative as **Sensitivity**.\n",
    "If I change the input $x$ slightly, how much does the output $y$ change?\n",
    "\n",
    "*   High derivative = Big change (Sensitive)\n",
    "*   Zero derivative = No change (Flat / Minimum / Maximum)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's visualize a loss function (Error curve)\n",
    "def loss_function(w):\n",
    "    return w**2  # Simple parabola\n",
    "\n",
    "w_values = np.linspace(-3, 3, 100)\n",
    "loss_values = loss_function(w_values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(w_values, loss_values, label='Loss Function $L(w) = w^2$')\n",
    "\n",
    "# Pick a point\n",
    "current_w = 2.0\n",
    "current_loss = loss_function(current_w)\n",
    "derivative = 2 * current_w  # d/dw (w^2) = 2w\n",
    "\n",
    "# Visualize the slope (tangent line)\n",
    "plt.plot(current_w, current_loss, 'ro', markersize=10, label='Current Weight')\n",
    "plt.arrow(current_w, current_loss, -1, -derivative, head_width=0.2, color='red', label='Negative Gradient (Downhill)')\n",
    "\n",
    "plt.title(f'Gradient at w={current_w} is {derivative}. To minimize loss, go LEFT!')\n",
    "plt.xlabel('Weight (w)')\n",
    "plt.ylabel('Error / Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient Descent: Walking Down the Hill\n",
    "This is how models learn.\n",
    "1.  Start at a random place (random weights).\n",
    "2.  Look around and find the steepest way down (compute Gradient).\n",
    "3.  Take a small step in that direction (Update weights).\n",
    "4.  Repeat until you hit the bottom (Minimum error).\n",
    "\n",
    "> **Analogy**: You are lost on a mountain in dense fog. You can only feel the slope under your feet. To get to the village at the bottom, you simply feel which way goes down and take a step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfb2 Part 3: Probability (Processing Uncertainty)\n",
    "## \"Predicting the Future in a Chaotic World\"\n",
    "\n",
    "The real world is messy. Data is noisy. Probability helps us build models that say \"I am 90% sure this is a cat\" rather than just \"Cat\".\n",
    "\n",
    "*   **Expectation**: The \"average\" outcome.\n",
    "*   **Variance**: How \"spread out\" or uncertain the data is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Normal Distribution (The Bell Curve)\n",
    "Most things in nature (heights, errors, noise) follow a **Normal Distribution**.\n",
    "It's defined by:\n",
    "*   **Mean ($\\mu$)**: The center.\n",
    "*   **Standard Deviation ($\\sigma$)**: The width.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate data from a normal distribution\n",
    "# Mean 0, Std Dev 1\n",
    "data = np.random.randn(1000)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data, kde=True, color='purple', bins=30)\n",
    "plt.title('The Normal Distribution (Bell Curve)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Mark the mean\n",
    "plt.axvline(np.mean(data), color='red', linestyle='--', label=f'Mean: {np.mean(data):.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Bayes' Theorem: Updating Beliefs\n",
    "This is the holy grail of reasoning. It tells us how to update our probability when we get new evidence.\n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} $$\n",
    "\n",
    "*   **Prior $P(A)$**: What I believed *before* seeing data.\n",
    "*   **Likelihood $P(B|A)$**: How likely the data is *if* my belief is true.\n",
    "*   **Posterior $P(A|B)$**: What I believe *after* seeing data.\n",
    "\n",
    "> **Example**: \n",
    "> *   Prior: \"It probably won't rain\" (It's summer).\n",
    "> *   Evidence: \"I see dark clouds\".\n",
    "> *   Posterior: \"Okay, it might rain now\" (Updated belief).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udf93 Conclusion: You are Ready!\n",
    "You now possess the three pillars of AI Math:\n",
    "1.  **Linear Algebra**: To represent and transform data.\n",
    "2.  **Calculus**: To optimize generic models and learn from data.\n",
    "3.  **Probability**: To handle uncertainty and reason about the world.\n",
    "\n",
    "### What's Next?\n",
    "*   Try changing the values in the code cells above.\n",
    "*   Build a simple neural network using `pytorch` or `tensorflow`.\n",
    "*   Remember: Math is a tool, not a barrier. You got this! \ud83d\ude80\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "authors": [
   {
    "name": "Tassawar Abbas",
    "email": "abbas829@gmail.com"
   }
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}